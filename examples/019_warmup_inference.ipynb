{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running multiple models with warm-up\n",
        "\n",
        "This notebook demonstrates how to load and run multiple AI models using DeGirum PySDK on a Hailo-8 or Hailo-8L device.\n",
        "\n",
        "It showcases the model warm-up technique, which involves running a single dummy inference on each model after loading. This step ensures all runtime resources and tensor buffers are initialized, which avoids latency spikes during the first real inference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Necessary Imports & loading models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "6hJTRobOV-9C",
        "outputId": "bac9a248-1cf8-4c00-9852-a563f941ebbd"
      },
      "outputs": [],
      "source": [
        "import cv2, numpy as np, degirum as dg\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 1. SETUP\n",
        "# ------------------------------------------------------------------\n",
        "host = \"@local\"\n",
        "zoo = \"degirum/hailo\"\n",
        "device_type = \"HAILORT/HAILO8L\"\n",
        "token=''\n",
        "pose_model_name = \"yolov8n_relu6_coco_pose--640x640_quant_hailort_hailo8l_1\"\n",
        "face_model_name = \"scrfd_500m--640x640_quant_hailort_hailo8l_1\"\n",
        "face_vec_model_name = \"arcface_mobilefacenet--112x112_quant_hailort_hailo8l_1\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Comparing latency with warmup and without warmup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time, numpy as np, degirum as dg\n",
        "\n",
        "# Load a Hailo model\n",
        "model = dg.load_model(\n",
        "    model_name=\"yolov8n_relu6_coco_pose--640x640_quant_hailort_hailo8l_1\",\n",
        "    inference_host_address=\"@cloud\",\n",
        "    token=\"dg_8PNGrkCskAPQooMPxoBRT8qBPSzac2cKoF2Qo\",\n",
        "    zoo_url=\"degirum/hailo\",\n",
        "    device_type=\"HAILORT/HAILO8L\"\n",
        ")\n",
        "\n",
        "dummy_input = np.zeros((640,640,3), dtype=np.uint8)\n",
        "\n",
        "# --- Inference WITHOUT warm-up ---\n",
        "start = time.time()\n",
        "_ = model(dummy_input)\n",
        "t1 = time.time() - start\n",
        "print(f\"First inference (no warm-up): {t1*1000:.1f} ms\")\n",
        "\n",
        "# --- Inference WITH warm-up ---\n",
        "_ = model(dummy_input)  # warm-up step\n",
        "\n",
        "start = time.time()\n",
        "_ = model(dummy_input)\n",
        "t2 = time.time() - start\n",
        "print(f\"Subsequent inference (warmed up): {t2*1000:.1f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Multi-model inference pipeline with warmup\n",
        "\n",
        "\n",
        "We run Pose detection continuously on every frame. If a dummy condition is met (e.g., more than one person detected), we run face detection model to localize faces and then we use face embedding (vector) model on each detected face. This showcases how using a dummy inference reduces latency while model switching"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Loading models and running warm-up inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "print(\"Loading models...\")\n",
        "PoseModel = dg.load_model(model_name=pose_model_name, inference_host_address=host, zoo_url=zoo, token=token, device_type=device_type)\n",
        "FaceModel = dg.load_model(model_name=face_model_name, inference_host_address=host, zoo_url=zoo, token=token, device_type=device_type)\n",
        "FaceVectorModel = dg.load_model(model_name=face_vec_model_name, inference_host_address=host, zoo_url=zoo, token=token, device_type=device_type)\n",
        "\n",
        "\n",
        "# Dummy image for warm-up\n",
        "dummy_pose_img = np.zeros((640,640,3), dtype=np.uint8)\n",
        "dummy_face_img = np.zeros((640,640,3), dtype=np.uint8)\n",
        "dummy_face_crop = np.zeros((112,112,3), dtype=np.uint8)\n",
        "\n",
        "print(\"Warming up models...\")\n",
        "PoseModel(dummy_pose_img)\n",
        "FaceModel(dummy_face_img)\n",
        "FaceVectorModel(dummy_face_crop)\n",
        "\n",
        "print(\"Warm-up complete. Models are ready for real-time inference.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Running inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbWu3KReY6uA"
      },
      "outputs": [],
      "source": [
        "\n",
        "cap = cv2.VideoCapture(0) # change to a file path or RTSP if needed\n",
        "\n",
        "while True:\n",
        "  ret, frame = cap.read()\n",
        "  if not ret: break\n",
        "\n",
        "  # --- Pose inference ---\n",
        "  pose_result = PoseModel(frame)\n",
        "  print(\"\\n========== POSE MODEL ==========\")\n",
        "  # print(f\"Raw Output: {pose_result} \\n \")\n",
        "  print(f\"Number of people detected: {len(pose_result.results)}\")\n",
        "  overlay = pose_result.image_overlay.copy()\n",
        "\n",
        "  # Dummy condition: run face inference only if >1 person detected\n",
        "  if len(pose_result.results) > 1:\n",
        "    print(f\"***** Condition met: {len(pose_result.results)} persons found\")\n",
        "\n",
        "    # --- Run Face Detection ---\n",
        "    face_result = FaceModel(frame)\n",
        "    print(\"\\n========== FACE DETECTION MODEL ==========\")\n",
        "    # print(f\"Raw Output: {face_result}\")\n",
        "    print(f\"Number of faces detected: {len(face_result.results)}\")\n",
        "    for face in face_result.results:\n",
        "      x1,y1,x2,y2 = map(int, face[\"bbox\"])\n",
        "      face_crop = frame[y1:y2, x1:x2]\n",
        "\n",
        "      # Resize to 112x112 for FaceVec\n",
        "      if face_crop.shape[0] > 0 and face_crop.shape[1] > 0:\n",
        "        face_resized = cv2.resize(face_crop, (112,112))\n",
        "        vec_result = FaceVectorModel(face_resized)\n",
        "        embedding = np.asarray(vec_result.results[0][\"data\"]).flatten()\n",
        "\n",
        "        # Optional: print embedding length or preview ID\n",
        "        print(\"\\n========== FACE VECTOR MODEL ==========\")\n",
        "        # print(f\"Raw Output: {vec_result}\")\n",
        "        print(f\"Embedding Length: {len(embedding)}\")\n",
        "        print(f\"Embedding Vector (first 5): {embedding[:5]}\")\n",
        "        print(f\"Embedding Norm: {np.linalg.norm(embedding)}\")\n",
        "        cv2.putText(overlay, f\"VecID: {embedding[0]:.2f}\", (x1, y1 - 10),\n",
        "            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)\n",
        "\n",
        "  # Show overlay\n",
        "  cv2.imshow(\"Pose + Optional Face Pipeline\", overlay)\n",
        "  if cv2.waitKey(1) & 0xFF in (ord('q'), ord('x')):\n",
        "    break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
"metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

