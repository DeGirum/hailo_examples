{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93313dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gi\n",
    "gi.require_version('Gst', '1.0')\n",
    "from gi.repository import Gst\n",
    "import cv2\n",
    "import numpy as np\n",
    "import degirum as dg\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9b5d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_frame_generator(video_source=\"Traffic.mp4\", target_size=(640, 640)):\n",
    "    \"\"\"\n",
    "    Generator that yields frames from a video source using GStreamer.\n",
    "    Resizes frames to target_size using GStreamer pipeline and yields both resized frame and frame_info.\n",
    "    \n",
    "    Args:\n",
    "        video_source: Video source (path to video file, e.g., \"Traffic.mp4\")\n",
    "        target_size: Tuple of (width, height) for resizing\n",
    "    \n",
    "    Yields:\n",
    "        tuple: (resized_frame, frame_info)\n",
    "            - resized_frame: Frame resized to target_size via GStreamer\n",
    "            - frame_info: Dict with 'original_frame', 'original_width', 'original_height'\n",
    "    \"\"\"\n",
    "    # Initialize GStreamer\n",
    "    Gst.init(None)\n",
    "    \n",
    "    # First, get original dimensions using OpenCV (one-time check)\n",
    "    cap = cv2.VideoCapture(video_source)\n",
    "    if not cap.isOpened():\n",
    "       raise ValueError(f\"Could not open video source: {video_source}\")\n",
    "    \n",
    "    ret, sample_frame = cap.read()\n",
    "    if not ret:\n",
    "       cap.release()\n",
    "       raise ValueError(\"Could not read sample frame to get dimensions\")\n",
    "    \n",
    "    original_height, original_width = sample_frame.shape[:2]\n",
    "    cap.release()\n",
    "\n",
    "    print(f\"Original video dimensions: {original_width}x{original_height}\")\n",
    "    print(f\"Target size: {target_size}\")\n",
    "    \n",
    "    # Create GStreamer pipeline for video file with tee to split into original and resized streams\n",
    "    target_width, target_height = target_size\n",
    "    pipeline_str = (\n",
    "        f\"filesrc location={video_source} ! \"\n",
    "        f\"decodebin ! videoconvert ! video/x-raw, format=BGR ! tee name=t \"\n",
    "        f\"t. ! queue ! appsink name=original_sink emit-signals=true max-buffers=1 drop=true \"\n",
    "        f\"t. ! queue ! videoscale ! video/x-raw, format=BGR, width={target_width}, height={target_height} ! \"\n",
    "        f\"appsink name=resized_sink emit-signals=true max-buffers=1 drop=true\"\n",
    "    )\n",
    "    \n",
    "    pipeline = Gst.parse_launch(pipeline_str)\n",
    "    original_sink = pipeline.get_by_name(\"original_sink\")\n",
    "    resized_sink = pipeline.get_by_name(\"resized_sink\")\n",
    "    \n",
    "    pipeline.set_state(Gst.State.PLAYING)\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            # Get resized frame\n",
    "            resized_sample = resized_sink.emit(\"pull-sample\")\n",
    "            if not resized_sample:\n",
    "                break\n",
    "                \n",
    "            # Get original frame\n",
    "            original_sample = original_sink.emit(\"pull-sample\")\n",
    "            if not original_sample:\n",
    "                break\n",
    "            \n",
    "            # Process resized frame\n",
    "            resized_buf = resized_sample.get_buffer()\n",
    "            resized_caps = resized_sample.get_caps()\n",
    "            resized_width = resized_caps.get_structure(0).get_value(\"width\")\n",
    "            resized_height = resized_caps.get_structure(0).get_value(\"height\")\n",
    "            \n",
    "            success, resized_map_info = resized_buf.map(Gst.MapFlags.READ)\n",
    "            if not success:\n",
    "                continue\n",
    "                \n",
    "            resized_frame = np.frombuffer(resized_map_info.data, np.uint8).reshape((resized_height, resized_width, 3))\n",
    "            resized_buf.unmap(resized_map_info)\n",
    "            \n",
    "            # Process original frame\n",
    "            original_buf = original_sample.get_buffer()\n",
    "            original_caps = original_sample.get_caps()\n",
    "            orig_width = original_caps.get_structure(0).get_value(\"width\")\n",
    "            orig_height = original_caps.get_structure(0).get_value(\"height\")\n",
    "            \n",
    "            success, original_map_info = original_buf.map(Gst.MapFlags.READ)\n",
    "            if not success:\n",
    "                continue\n",
    "                \n",
    "            original_frame = np.frombuffer(original_map_info.data, np.uint8).reshape((orig_height, orig_width, 3))\n",
    "            original_buf.unmap(original_map_info)\n",
    "            \n",
    "            # Create frame_info dictionary\n",
    "            frame_info = {\n",
    "                'original_frame': original_frame.copy(),\n",
    "                'original_width': orig_width,\n",
    "                'original_height': orig_height\n",
    "            }\n",
    "            \n",
    "            yield resized_frame, frame_info\n",
    "                \n",
    "    finally:\n",
    "        pipeline.set_state(Gst.State.NULL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6227af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPostprocessor(dg.postprocessor.DetectionResults):\n",
    "    \"\"\"\n",
    "    Custom postprocessor that plots results on the original frame using frame_info.\n",
    "    Frame info can be accessed via results.info.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_image, model_image, inference_results, **kwargs):\n",
    "        # Initialize parent class\n",
    "        super().__init__(\n",
    "            input_image=input_image,\n",
    "            model_image=model_image, \n",
    "            inference_results=inference_results,\n",
    "            **kwargs\n",
    "        )\n",
    "    \n",
    "    def plot_results_on_original(self):\n",
    "        \"\"\"\n",
    "        Plot detection results on the original frame (not resized frame).\n",
    "        Uses frame_info from results.info to get original frame and dimensions.\n",
    "        \"\"\"\n",
    "        # Access frame_info from results.info\n",
    "        if not hasattr(self, 'info') or self.info is None:\n",
    "            print(\"Warning: frame_info not available in results.info\")\n",
    "            return self.input_image\n",
    "        \n",
    "        frame_info = self.info\n",
    "        original_frame = frame_info['original_frame'].copy()\n",
    "        original_width = frame_info['original_width']\n",
    "        original_height = frame_info['original_height']\n",
    "        \n",
    "        # Get detection results\n",
    "        detections = self.results\n",
    "        \n",
    "        # Calculate scaling factors from resized (640x640) to original dimensions\n",
    "        scale_x = original_width / 640\n",
    "        scale_y = original_height / 640\n",
    "        \n",
    "        # Plot each detection on the original frame\n",
    "        for detection in detections:\n",
    "            if 'bbox' in detection:\n",
    "                # Scale bounding box coordinates back to original frame size\n",
    "                x1, y1, x2, y2 = detection['bbox']\n",
    "                x1 = int(x1 * scale_x)\n",
    "                y1 = int(y1 * scale_y) \n",
    "                x2 = int(x2 * scale_x)\n",
    "                y2 = int(y2 * scale_y)\n",
    "                \n",
    "                # Draw bounding box\n",
    "                cv2.rectangle(original_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                \n",
    "                # Draw label if available\n",
    "                if 'label' in detection:\n",
    "                    label = detection['label']\n",
    "                    score = detection.get('score', 0)\n",
    "                    text = f\"{label}: {score:.2f}\"\n",
    "                    \n",
    "                    # Calculate text size and position\n",
    "                    (text_width, text_height), baseline = cv2.getTextSize(\n",
    "                        text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2\n",
    "                    )\n",
    "                    \n",
    "                    # Draw text background\n",
    "                    cv2.rectangle(\n",
    "                        original_frame,\n",
    "                        (x1, y1 - text_height - baseline - 5),\n",
    "                        (x1 + text_width, y1),\n",
    "                        (0, 255, 0), -1\n",
    "                    )\n",
    "                    \n",
    "                    # Draw text\n",
    "                    cv2.putText(\n",
    "                        original_frame,\n",
    "                        text,\n",
    "                        (x1, y1 - baseline - 5),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.6,\n",
    "                        (0, 0, 0),\n",
    "                        2\n",
    "                    )\n",
    "        \n",
    "        return original_frame\n",
    "    \n",
    "    @property\n",
    "    def image_overlay(self):\n",
    "        \"\"\"Override image_overlay to return the original frame with detections plotted.\"\"\"\n",
    "        return self.plot_results_on_original()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934b2d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(output_dir=\"result_frames\", max_frames=100):\n",
    "    \"\"\"\n",
    "    Main function demonstrating the video generator and custom postprocessor.\n",
    "    Saves result frames to a directory instead of displaying them.\n",
    "    \n",
    "    Args:\n",
    "        output_dir: Directory to save result frames\n",
    "        max_frames: Maximum number of frames to process (0 for unlimited)\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"Created output directory: {output_dir}\")\n",
    "    else:\n",
    "        print(f\"Saving frames to existing directory: {output_dir}\")\n",
    "    \n",
    "    # Load your model (adjust model_name and other parameters as needed)\n",
    "    try:\n",
    "        model = dg.load_model(\n",
    "            model_name=\"yolov8n_coco--640x640_quant_hailort_multidevice_1\",\n",
    "            inference_host_address=\"@local\",\n",
    "            zoo_url=\"degirum/hailo\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        print(\"Please adjust the model parameters for your setup\")\n",
    "        return\n",
    "    \n",
    "    # Attach the custom postprocessor\n",
    "    model.custom_postprocessor = CustomPostprocessor\n",
    "    \n",
    "    # Warmup inference\n",
    "    print(\"Performing warmup inference...\")\n",
    "    dummy_frame = np.zeros((640, 640, 3), dtype=np.uint8)\n",
    "    _ = model.predict(dummy_frame)\n",
    "    print(\"Warmup complete\")\n",
    "    \n",
    "    # Create a wrapper generator that provides frame_info in the correct format\n",
    "    def model_input_generator():\n",
    "        for resized_frame, frame_info in video_frame_generator(video_source=\"Traffic.mp4\"):\n",
    "            # Yield the resized frame for model inference\n",
    "            # The frame_info will be attached to results.info\n",
    "            yield resized_frame, frame_info\n",
    "    \n",
    "    # FPS tracking\n",
    "    frame_count = 0\n",
    "    saved_frames = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(f\"Starting video inference... Will save up to {max_frames if max_frames > 0 else 'unlimited'} frames\")\n",
    "    \n",
    "    try:\n",
    "        # Run inference on video frames\n",
    "        for result in model.predict_batch(model_input_generator()):\n",
    "            # The frame_info is now available in result.info\n",
    "            # The custom postprocessor will use it to plot on original frame\n",
    "            \n",
    "            frame_count += 1\n",
    "            \n",
    "            # Save the result frame (original frame with detections)\n",
    "            frame_filename = os.path.join(output_dir, f\"frame_{saved_frames:06d}.jpg\")\n",
    "            success = cv2.imwrite(frame_filename, result.image_overlay)\n",
    "            \n",
    "            if success:\n",
    "                saved_frames += 1\n",
    "                if saved_frames % 10 == 0:  # Print progress every 10 saved frames\n",
    "                    print(f\"Saved {saved_frames} frames\")\n",
    "            else:\n",
    "                print(f\"Failed to save frame {saved_frames}\")\n",
    "            \n",
    "            elapsed_time = time.time() - start_time\n",
    "            \n",
    "            # Print FPS every second\n",
    "            if elapsed_time >= 1.0:\n",
    "                fps = frame_count / elapsed_time\n",
    "                print(f\"Processing FPS: {fps:.2f} | Saved frames: {saved_frames}\")\n",
    "                frame_count = 0\n",
    "                start_time = time.time()\n",
    "            \n",
    "            # Stop if max_frames reached\n",
    "            if max_frames > 0 and saved_frames >= max_frames:\n",
    "                print(f\"Reached maximum frames limit: {max_frames}\")\n",
    "                break\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted by user\")\n",
    "    finally:\n",
    "        print(f\"Total frames saved: {saved_frames}\")\n",
    "        print(f\"Frames saved in directory: {output_dir}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6684895",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
