{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26434ae6-4a29-438f-b25a-fb842a5a6808",
   "metadata": {},
   "source": [
    "# Multi-Model Multi-Stream Inference with DeGirum PySDK\n",
    "This notebook example show how to build multi-model multi-stream apps using DeGirum PySDK and degirum_tools. <br>\n",
    "Three common patterns are: <br>\n",
    "\n",
    "    -3 models, 3 video streams â€” each in its own thread.\n",
    "    -3 models, 1 video stream â€” fuse results with a compound model and a manual fusion variant.\n",
    "    -3 models, 3 video streams â€” iterate results together in one loop (single-threaded)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be6be88-ae65-483f-ae94-795e5d5d1af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure degirum-tools package is installed\n",
    "!pip show degirum-tools || pip install degirum-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906094c5-5543-4241-ab87-b0f91336697f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from degirum_tools import ModelSpec\n",
    "from degirum_tools import remote_assets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f99576-1352-4499-a80e-b0c714903859",
   "metadata": {},
   "source": [
    "**ModelSpec**: One place to define the models (Declare models once and load them consistently, also keep device/runtime details in model_properties).\n",
    "This example uses DeGirumâ€™s Hailo zoo by default. Swap model names/zoo to match your project as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e93364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Specify where to run the inference ===\n",
    "# hw_location: where you want to run inference\n",
    "#     \"@cloud\" to use DeGirum cloud\n",
    "#     \"@local\" to run on local machine\n",
    "#     IP address for AI server inference\n",
    "# model_zoo_url: url/path for model zoo\n",
    "#     cloud_zoo_url: valid for @cloud, @local, and ai server inference options\n",
    "#     '': ai server serving models from local folder\n",
    "#     path to json file: single model zoo in case of @local inference\n",
    "hw_location = \"@local\"\n",
    "model_zoo_url = \"degirum/hailo\"\n",
    "\n",
    "# === Sources (define once, reuse everywhere) ===\n",
    "src1 = 0  # webcam (or your device index)\n",
    "src2 = remote_assets.person_face_hand  # sample clip / replace with your path/URL\n",
    "src3 = remote_assets.person_face_hand  # another source (replace as needed)\n",
    "\n",
    "# === Model specs ===\n",
    "model1_spec = ModelSpec(\n",
    "    model_name=\"yolov8n_relu6_face--640x640_quant_hailort_multidevice_1\",\n",
    "    zoo_url=model_zoo_url,\n",
    "    inference_host_address=hw_location,\n",
    "    model_properties={\"device_type\": [\"HAILORT/HAILO8L\"]},\n",
    ")\n",
    "\n",
    "model2_spec = ModelSpec(\n",
    "    model_name=\"yolov8n_relu6_hand--640x640_quant_hailort_multidevice_1\",\n",
    "    zoo_url=model_zoo_url,\n",
    "    inference_host_address=hw_location,\n",
    "    model_properties={\"device_type\": [\"HAILORT/HAILO8L\"]},\n",
    ")\n",
    "\n",
    "model3_spec = ModelSpec(\n",
    "    model_name=\"yolov8n_relu6_person--640x640_quant_hailort_multidevice_1\",\n",
    "    zoo_url=model_zoo_url,\n",
    "    inference_host_address=hw_location,\n",
    "    model_properties={\"device_type\": [\"HAILORT/HAILO8L\"]},\n",
    ")\n",
    "\n",
    "# === Load model objects from specs (simple) ===\n",
    "model1 = model1_spec.load_model()\n",
    "model2 = model2_spec.load_model()\n",
    "model3 = model3_spec.load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5c9003-fdf1-43fb-b81b-67913fb34e65",
   "metadata": {},
   "source": [
    "## Use Case 1: 3 models, 3 video streams (each in a separate thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867230b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import degirum_tools\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Map models to sources and labels\n",
    "configurations = [\n",
    "    {\"model\": model1, \"source\": src1, \"display_name\": \"Model 1 (Face)\"},\n",
    "    {\"model\": model2, \"source\": src2, \"display_name\": \"Model 2 (Hand)\"},\n",
    "    {\"model\": model3, \"source\": src3, \"display_name\": \"Model 3 (Person)\"},\n",
    "]\n",
    "\n",
    "\n",
    "# Single-stream runner\n",
    "def run_inference(model, source, display_name):\n",
    "    with degirum_tools.Display(display_name) as output_display:\n",
    "        for inference_result in degirum_tools.predict_stream(model, source):\n",
    "            output_display.show(inference_result)\n",
    "    print(f\"âœ… Stream '{display_name}' has finished.\")\n",
    "\n",
    "\n",
    "# Launch independent threads\n",
    "threads = []\n",
    "for cfg in configurations:\n",
    "    t = threading.Thread(\n",
    "        target=run_inference,\n",
    "        args=(cfg[\"model\"], cfg[\"source\"], cfg[\"display_name\"]),\n",
    "        daemon=True,\n",
    "    )\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "\n",
    "# Wait for all threads to complete\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print(\"ðŸŽ‰ All inference streams have been processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ea4c0d-2180-4a38-8be8-885117788f3e",
   "metadata": {},
   "source": [
    "## Use Case 2: 3 models, 1 video stream (combine results)\n",
    "Two options here:\n",
    "\n",
    "    A) Compound model (simplest) - Let the tooling fuse results for you using CombiningCompoundModel.\n",
    "    B) Manual fusion (more control) - Run three predictors off the same video stream and merge results yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bae0547-38dd-45ea-997b-049f298e0b6a",
   "metadata": {},
   "source": [
    "### Compound model (simplest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433f1cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import degirum_tools\n",
    "\n",
    "# Use the first source for the single-stream case\n",
    "video_source = src1\n",
    "\n",
    "# Compose a compound model from your three models\n",
    "combined_model = degirum_tools.CombiningCompoundModel(\n",
    "    degirum_tools.CombiningCompoundModel(model2, model1),\n",
    "    model3,\n",
    ")\n",
    "\n",
    "# Stream + display\n",
    "with degirum_tools.Display(\"Compound: Models 1+2+3\") as display:\n",
    "    for inference_result in degirum_tools.predict_stream(combined_model, video_source):\n",
    "        display.show(inference_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320c80d3-310e-4ffa-a434-063ede00e9c4",
   "metadata": {},
   "source": [
    "### Manual fusion (more control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61ed392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import degirum_tools\n",
    "from itertools import zip_longest\n",
    "\n",
    "with degirum_tools.Display(\n",
    "    \"Manual Fusion (Single Stream)\"\n",
    ") as display, degirum_tools.open_video_stream(src1) as video_stream:\n",
    "\n",
    "    # Create prediction generators bound to the same underlying stream\n",
    "    p1 = model1.predict_batch(degirum_tools.video_source(video_stream))\n",
    "    p2 = model2.predict_batch(degirum_tools.video_source(video_stream))\n",
    "    p3 = model3.predict_batch(degirum_tools.video_source(video_stream))\n",
    "\n",
    "    # Iterate in lockstep; guard against None frames\n",
    "    for r1, r2, r3 in zip_longest(p1, p2, p3):\n",
    "        if r1 is None or r2 is None or r3 is None:\n",
    "            continue\n",
    "\n",
    "        # Merge detections into one result; reuse r1 as the carrier\n",
    "        r1.results.extend(r2.results)\n",
    "        r1.results.extend(r3.results)\n",
    "\n",
    "        display.show(r1.image_overlay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e092f91-2643-461a-b8de-c049e2623a76",
   "metadata": {},
   "source": [
    "## Use Case 3: 3 models, 3 video streams (iterated together in a single thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6392eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import degirum_tools\n",
    "from itertools import zip_longest\n",
    "\n",
    "# Use a separate display per stream\n",
    "with degirum_tools.Display(\"Model 1 (src1)\") as d1, degirum_tools.Display(\n",
    "    \"Model 2 (src2)\"\n",
    ") as d2, degirum_tools.Display(\"Model 3 (src3)\") as d3, degirum_tools.open_video_stream(\n",
    "    src1\n",
    ") as s1, degirum_tools.open_video_stream(\n",
    "    src2\n",
    ") as s2, degirum_tools.open_video_stream(\n",
    "    src3\n",
    ") as s3:\n",
    "\n",
    "    # Create prediction generators\n",
    "    p1 = model1.predict_batch(degirum_tools.video_source(s1))\n",
    "    p2 = model2.predict_batch(degirum_tools.video_source(s2))\n",
    "    p3 = model3.predict_batch(degirum_tools.video_source(s3))\n",
    "\n",
    "    # Advance all three streams in lockstep\n",
    "    for r1, r2, r3 in zip_longest(p1, p2, p3):\n",
    "        if r1 is not None:\n",
    "            d1.show(r1)\n",
    "        if r2 is not None:\n",
    "            d2.show(r2)\n",
    "        if r3 is not None:\n",
    "            d3.show(r3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
