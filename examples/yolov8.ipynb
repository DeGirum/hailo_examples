{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unified Inference and Visualization for YOLO Model Variants\n",
    "This notebook demonstrates running different flavors of YOLO models (e.g., image classification, object detection, pose estimation, and segmentation) \n",
    "using a unified codebase with the DeGirum PySDK and tools. Key features include:\n",
    "\n",
    "- Unified handling of YOLO model variants with minimal changes to the code.\n",
    "- Flexible selection of inference host (cloud or local) and model zoo location.\n",
    "- Seamless output visualization, regardless of the specific YOLO model used.\n",
    "\n",
    "Simply uncomment a model of your choice, provide the necessary configurations, and run the code block \n",
    "to perform inference and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running inference using 'yolov8n_relu6_coco--640x640_quant_hailort_hailo8l_1' on image source '../assets/ThreePersons.jpg'\n",
      "- bbox: [50.34862518310547, 11.273429870605469, 259.01898193359375, 421.975830078125]\n",
      "  category_id: 0\n",
      "  label: person\n",
      "  score: 0.9210436940193176\n",
      "- bbox: [425.5379333496094, 20.12468719482422, 640.0, 353.85784912109375]\n",
      "  category_id: 0\n",
      "  label: person\n",
      "  score: 0.888812780380249\n",
      "- bbox: [217.6569366455078, 45.100433349609375, 453.69573974609375, 402.4808654785156]\n",
      "  category_id: 0\n",
      "  label: person\n",
      "  score: 0.8193221092224121\n",
      "\n",
      "Press 'x' or 'q' to stop.\n"
     ]
    }
   ],
   "source": [
    "import degirum as dg, degirum_tools\n",
    "\n",
    "# choose a model to run inference on by uncommenting one of the following lines\n",
    "model_name = \"yolov8n_relu6_coco--640x640_quant_hailort_hailo8l_1\"\n",
    "# model_name = \"yolov8n_relu6_coco_pose--640x640_quant_hailort_hailo8l_1\"\n",
    "# model_name = \"yolov8n_relu6_coco_seg--640x640_quant_hailort_hailo8l_1\"\n",
    "# model_name = \"yolov8s_silu_imagenet--224x224_quant_hailort_hailo8l_1\"\n",
    "\n",
    "# choose inference host address\n",
    "inference_host_address = \"@cloud\" \n",
    "# inference_host_address = \"@local\"\n",
    "\n",
    "# choose zoo_url\n",
    "zoo_url = \"degirum/models_hailort\"\n",
    "# zoo_url = \"<path to local folder>\"\n",
    "\n",
    "# choose image source\n",
    "image_source = \"../assets/ThreePersons.jpg\"\n",
    "\n",
    "# set token\n",
    "token = degirum_tools.get_token()\n",
    "# token = '' # leave empty for local inference\n",
    "\n",
    "# load AI model\n",
    "model = dg.load_model(\n",
    "    model_name=model_name,\n",
    "    inference_host_address=inference_host_address,\n",
    "    zoo_url=zoo_url,\n",
    "    token=token\n",
    ")\n",
    "\n",
    "# perform AI model inference on given image source\n",
    "print(f\" Running inference using '{model_name}' on image source '{image_source}'\")\n",
    "inference_result = model(image_source)\n",
    "\n",
    "# print('Inference Results \\n', inference_result)  # numeric results\n",
    "print(inference_result)\n",
    "print(\"Press 'x' or 'q' to stop.\")\n",
    "\n",
    "# show results of inference\n",
    "with degirum_tools.Display(\"AI Camera\") as output_display:\n",
    "    output_display.show_image(inference_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "def rearrange_detections(detections):\n",
    "    \n",
    "    # Extract y-centers of bounding boxes\n",
    "    y_centers = np.array([[(det[\"bbox\"][1] + det[\"bbox\"][3]) / 2] for det in detections])\n",
    "\n",
    "    # Check if all y-centers are within a small range (indicating a single line)\n",
    "    if len(detections) <= 1 or np.max(y_centers) - np.min(y_centers) < 20:  # Adjust threshold as needed\n",
    "        # Sort detections by the x_min value\n",
    "        detections_sorted = sorted(detections, key=lambda det: det[\"bbox\"][0])\n",
    "        # Concatenate all labels into a single line\n",
    "        first_line_labels = \"\".join([det[\"label\"] for det in detections_sorted])\n",
    "        second_line_labels = \"\"  # No second line\n",
    "    else:\n",
    "        # Apply KMeans clustering to group detections into two lines\n",
    "        kmeans = KMeans(n_clusters=2, random_state=0).fit(y_centers)\n",
    "        labels = kmeans.labels_\n",
    "\n",
    "        # Separate detections into two lines based on clustering labels\n",
    "        line_0 = [det for i, det in enumerate(detections) if labels[i] == 0]\n",
    "        line_1 = [det for i, det in enumerate(detections) if labels[i] == 1]\n",
    "\n",
    "        # Determine the order of lines based on the average y-center\n",
    "        avg_y_line_0 = np.mean([((det[\"bbox\"][1] + det[\"bbox\"][3]) / 2) for det in line_0])\n",
    "        avg_y_line_1 = np.mean([((det[\"bbox\"][1] + det[\"bbox\"][3]) / 2) for det in line_1])\n",
    "\n",
    "        if avg_y_line_0 < avg_y_line_1:\n",
    "            first_line = line_0\n",
    "            second_line = line_1\n",
    "        else:\n",
    "            first_line = line_1\n",
    "            second_line = line_0\n",
    "\n",
    "        # Sort each line by the x_min value (first value in bbox)\n",
    "        first_line_sorted = sorted(first_line, key=lambda det: det[\"bbox\"][0])\n",
    "        second_line_sorted = sorted(second_line, key=lambda det: det[\"bbox\"][0])\n",
    "\n",
    "        # Concatenate all labels in sorted order for each line\n",
    "        first_line_labels = \"\".join([det[\"label\"] for det in first_line_sorted])\n",
    "        second_line_labels = \"\".join([det[\"label\"] for det in second_line_sorted])\n",
    "\n",
    "    # Return the labels for both lines\n",
    "    return first_line_labels, second_line_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running inference using 'yolov8n_relu6_lp_ocr--256x128_float_openvino_multidevice_1' on image source 'C://Users//ShashiChilappagari//Downloads//rh2.jpeg'\n",
      "123456 \n"
     ]
    }
   ],
   "source": [
    "import degirum as dg, degirum_tools\n",
    "\n",
    "# choose a model to run inference on by uncommenting one of the following lines\n",
    "model_name = \"yolov8n_relu6_lp_ocr--256x128_float_openvino_multidevice_1\"\n",
    "# model_name = \"yolov8n_relu6_coco_pose--640x640_quant_hailort_hailo8l_1\"\n",
    "# model_name = \"yolov8n_relu6_coco_seg--640x640_quant_hailort_hailo8l_1\"\n",
    "# model_name = \"yolov8s_silu_imagenet--224x224_quant_hailort_hailo8l_1\"\n",
    "\n",
    "# choose inference host address\n",
    "inference_host_address = \"@cloud\" \n",
    "# inference_host_address = \"@local\"\n",
    "\n",
    "# choose zoo_url\n",
    "zoo_url = \"degirum/models_openvino\"\n",
    "# zoo_url = \"<path to local folder>\"\n",
    "\n",
    "# choose image source\n",
    "image_source = \"C://Users//ShashiChilappagari//Downloads//rh2.jpeg\"\n",
    "\n",
    "# set token\n",
    "token = degirum_tools.get_token()\n",
    "# token = '' # leave empty for local inference\n",
    "\n",
    "# load AI model\n",
    "model = dg.load_model(\n",
    "    model_name=model_name,\n",
    "    inference_host_address=inference_host_address,\n",
    "    zoo_url=zoo_url,\n",
    "    token=token,\n",
    "    output_confidence_threshold=0.2\n",
    ")\n",
    "\n",
    "# perform AI model inference on given image source\n",
    "print(f\" Running inference using '{model_name}' on image source '{image_source}'\")\n",
    "inference_result = model(image_source)\n",
    "\n",
    "# print('Inference Results \\n', inference_result)  # numeric results\n",
    "# print(inference_result)\n",
    "# print(\"Press 'x' or 'q' to stop.\")\n",
    "\n",
    "labels1, labels2= rearrange_detections(inference_result.results)\n",
    "print(labels1, labels2)\n",
    "# # show results of inference\n",
    "# with degirum_tools.Display(\"AI Camera\") as output_display:\n",
    "#     output_display.show_image(inference_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "def rearrange_detections(detections):\n",
    "    \n",
    "    # Sort the detections by the x_min value (first value in bbox)\n",
    "    sorted_detections = sorted(detections, key=lambda det: det[\"bbox\"][0])\n",
    "\n",
    "    # Concatenate all labels in sorted order\n",
    "    concatenated_labels = \"\".join([det[\"label\"] for det in sorted_detections])\n",
    "\n",
    "    # Return the concatenated labels\n",
    "    return concatenated_labels\n",
    "\n",
    "def run_inference_on_folder(input_folder, output_folder, model):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for image_file in os.listdir(input_folder):\n",
    "        if image_file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            # Load image\n",
    "            image_path = os.path.join(input_folder, image_file)\n",
    "            print(image_path)\n",
    "            # image = cv2.imread(image_path)\n",
    "\n",
    "            # Run inference (replace this with the actual inference function)\n",
    "            results = model(image_path)\n",
    "\n",
    "            # Rearrange detections and get concatenated labels\n",
    "            concatenated_labels = rearrange_detections(results.results)\n",
    "\n",
    "            # Overlay labels on the image\n",
    "            annotated_image = results.image.copy()\n",
    "            height, width, _ = annotated_image.shape\n",
    "\n",
    "            band_height = 50\n",
    "            annotated_image = cv2.copyMakeBorder(results.image, 0, band_height, 0, 0, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "\n",
    "            # Add text on the black band\n",
    "            cv2.putText(\n",
    "                annotated_image,\n",
    "                concatenated_labels,\n",
    "                (10, height + band_height - 15),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                1,\n",
    "                (255, 255, 255),\n",
    "                2\n",
    "            )\n",
    "\n",
    "            # Save the annotated image\n",
    "            output_path = os.path.join(output_folder, os.path.splitext(image_file)[0] + \"_annotated.jpg\")\n",
    "            cv2.imwrite(output_path, annotated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Alabama.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Alaska.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Arizona.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Arkansas.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\California.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Colorado.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Connecticut.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Delaware.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\DistrictOfColumbia.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Florida.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Georgia.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Guam.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Hawaii.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Idaho.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Illinois.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Indiana.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Iowa.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Kansas.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Kentucky.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Louisiana.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Maine.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Maryland.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Massachusetts.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Michigan.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Minnesota.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Mississippi.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Missouri.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Montana.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Nebraska.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Nevada.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\NewHampshire.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\NewJersey.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\NewMexico.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\NewYork.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\NorthCarolina.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\NorthDakota.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Ohio.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Oklahoma.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Oregon.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Pennsylvania.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\PuertoRico.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\RhodeIsland.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\SouthCarolina.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\SouthDakota.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Tennessee.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Texas.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Utah.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Vermont.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Virginia.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Washington.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\WestVirginia.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Wisconsin.jpg\n",
      "C:\\Users\\ShashiChilappagari\\Documents\\Python_Scripts\\Datasets\\FiftyStatesLicPlates\\FiftyStatesLicensePlates\\Wyoming.jpg\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "input_folder = \"C:\\\\Users\\\\ShashiChilappagari\\\\Documents\\\\Python_Scripts\\\\Datasets\\\\FiftyStatesLicPlates\\\\FiftyStatesLicensePlates\"\n",
    "output_folder = \"C:\\\\Users\\\\ShashiChilappagari\\\\Documents\\\\Python_Scripts\\\\Datasets\\\\FiftyStatesLicPlates\\\\annotated\"\n",
    "model.output_confidence_threshold = 0.2\n",
    "run_inference_on_folder(input_folder, output_folder, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "supervision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
