{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Emotion Recognition Inference with DeGirum PySDK</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates emotion recognition using DeGirum PySDK on Hailo hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import cv2\n",
    "import numpy as np\n",
    "import degirum as dg, degirum_tools\n",
    "\n",
    "# Connection parameters\n",
    "inference_host_address = \"@local\"\n",
    "zoo_url = \"degirum/hailo\"\n",
    "token = \"<dg_token>\"\n",
    "# Device types can be adjusted as needed\n",
    "device_type = \"HAILORT/HAILO8L\"\n",
    "\n",
    "# Choose model names\n",
    "face_det_model_name = \"yolov8n_relu6_widerface_kpts--640x640_quant_hailort_hailo8l_1\"\n",
    "emotion_model_name = \"emotion_recognition_fer2013--64x64_quant_hailort_multidevice_1\"\n",
    "\n",
    "# Choose image source\n",
    "image_source = \"<image_path>\"\n",
    "\n",
    "# Load the face detection model\n",
    "print(f\"Running face detection using '{face_det_model_name}' on image '{image_source}'\")\n",
    "face_model = dg.load_model(\n",
    "    model_name=face_det_model_name,\n",
    "    inference_host_address=inference_host_address,\n",
    "    zoo_url=zoo_url,\n",
    "    token=token,\n",
    "    device_type=device_type\n",
    ")\n",
    "\n",
    "# Load the emotion classifier model\n",
    "print(f\"Loading emotion classifier '{emotion_model_name}'\")\n",
    "emotion_model = dg.load_model(\n",
    "    model_name=emotion_model_name,\n",
    "    inference_host_address=inference_host_address,\n",
    "    zoo_url=zoo_url,\n",
    "    token=token,\n",
    "    device_type=device_type\n",
    ")\n",
    "\n",
    "# Perform face detection inference\n",
    "face_detection_result = face_model(image_source)\n",
    "print(\"Face Detection Results:\", face_detection_result.results)\n",
    "\n",
    "# Read the original image using OpenCV\n",
    "image = cv2.imread(image_source)\n",
    "if image is None:\n",
    "    raise ValueError(f\"Unable to read image from {image_source}\")\n",
    "\n",
    "# Process each detected face\n",
    "if face_detection_result.results:\n",
    "    for idx, detection in enumerate(face_detection_result.results):\n",
    "        bbox = detection['bbox']  # Expected format: [x1, y1, x2, y2]\n",
    "        x1, y1, x2, y2 = map(int, bbox)\n",
    "        \n",
    "        # Crop the face from the image\n",
    "        face_crop = image[y1:y2, x1:x2]\n",
    "        \n",
    "        # Resize the face crop to 256x256 for emotion classification\n",
    "        face_crop_resized = cv2.resize(face_crop, (256, 256))\n",
    "        \n",
    "        # Run emotion classification on the face crop\n",
    "        emotion_result = emotion_model(face_crop_resized)\n",
    "        final_emotion = max(emotion_result.results, key=lambda x: x['score'])\n",
    "        print(f\"Face {idx} final emotion: {final_emotion['label']}\")\n",
    "        \n",
    "        # Annotate the face crop with the predicted emotion label\n",
    "        cv2.putText(face_crop_resized, final_emotion['label'], (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        # Display the annotated face crop using degirum_tools.Display\n",
    "        with degirum_tools.Display(f\"Face {idx} Emotion\") as output_display:\n",
    "            output_display.show_image(face_crop_resized)\n",
    "else:\n",
    "    print(\"No face detected.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
